{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhC2_BGOqEm1"
   },
   "source": [
    "# LINEAR REGRESSION - n Variable\n",
    "\n",
    "**Model: **\n",
    "$$ \\hat{y} = w_1 x_1 + w_2 x_2 + ... + w_n x_n + b$$\n",
    "\n",
    "**Loss function: **\n",
    "$$ \\mathcal{L} (a) = \\frac{1}{2m} \\sum ^{m} _{i=1} (\\hat{y} - y)^{2} $$\n",
    "\n",
    "**Loss function derivative (gradient, slope): **\n",
    "$$ \\mathcal{L}' (w_1) = \\frac{\\partial \\mathcal{L}}{\\partial w_1} = \\frac{1}{m} \\sum ^{m} _{i=1} (\\hat{y} - y) x_1 $$ \n",
    "$$ \\mathcal{L}' (w_2) = \\frac{\\partial \\mathcal{L}}{\\partial w_2} = \\frac{1}{m} \\sum ^{m} _{i=1} (\\hat{y} - y) x_2 $$ \n",
    "$$ ... $$\n",
    "$$ \\mathcal{L}' (w_n) = \\frac{\\partial \\mathcal{L}}{\\partial w_n} = \\frac{1}{m} \\sum ^{m} _{i=1} (\\hat{y} - y) x_n $$ \n",
    "$$ \\mathcal{L}' (b) = \\frac{\\partial \\mathcal{L}}{\\partial b} = \\frac{1}{m} \\sum ^{m} _{i=1} (\\hat{y} - y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "24gJBvHHqTZd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4dbv-bsgqaUt"
   },
   "source": [
    "**Implement with for-loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Nz60r8MFqb2a"
   },
   "outputs": [],
   "source": [
    "class model_1():\n",
    "    def __init__(self,\n",
    "                X_train,\n",
    "                Y_train,\n",
    "                num_step = 10000,\n",
    "                lr = 0.1):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.num_step = num_step\n",
    "        self.lr = lr\n",
    "        \n",
    "    # Initialize weight and bias\n",
    "    def initialize(self):\n",
    "        self.W = [0 for _ in range(len(self.X_train[0]))]\n",
    "        self.b = 0\n",
    "\n",
    "    # Prediction of 1 data point\n",
    "    def predict(self, x):\n",
    "        y_hat = 0;\n",
    "        for i in range(len(self.W)):\n",
    "            y_hat += self.W[i] * x[i]\n",
    "\n",
    "        y_hat += self.b\n",
    "        return y_hat\n",
    "\n",
    "    # Gradient of 1 data point\n",
    "    def grad(self,x, y):\n",
    "        dW = []\n",
    "        db = 0\n",
    "        y_hat = self.predict(x)\n",
    "        \n",
    "        for i in range(len(self.W)):\n",
    "            dW.append((y_hat - y) * x[i])\n",
    "\n",
    "        db = (y_hat - y)\n",
    "\n",
    "        return {\"dW\":dW, \"db\" : db}\n",
    "\n",
    "    # Gradient of all data point\n",
    "    def grads(self):\n",
    "        dW = [0 for _ in range(len(self.W))]\n",
    "        db = 0\n",
    "        m = len(self.Y_train)\n",
    "\n",
    "        for i in range(m):\n",
    "            x = self.X_train[i]\n",
    "            y = self.Y_train[i]\n",
    "            gradient = self.grad(x,y)\n",
    "            for j in range(len(gradient[\"dW\"])):\n",
    "                dW[j] += gradient[\"dW\"][j]/m\n",
    "            db += gradient[\"db\"]/m\n",
    "\n",
    "        return {\"dW\":dW, \"db\" : db}\n",
    "\n",
    "    # Calculate loss with respect to W and b\n",
    "    def loss(self):\n",
    "        total = 0\n",
    "        m = len(self.Y_train)\n",
    "        for i in range(m):\n",
    "            x = self.X_train[i]\n",
    "            y = self.Y_train[i]\n",
    "            y_hat = self.predict(x)\n",
    "            total = total + (y_hat - y)**2\n",
    "        return total* 1 / (2*m)\n",
    "\n",
    "    def train(self):\n",
    "        self.initialize()\n",
    "        for i in range(self.num_step):\n",
    "            gradient = self.grads()\n",
    "            for j in range(len(self.W)):\n",
    "                self.W[j] = self.W[j] - self.lr * gradient[\"dW\"][j]\n",
    "\n",
    "            self.b = self.b - self.lr * gradient[\"db\"]\n",
    "\n",
    "            if i%500==0:\n",
    "                print(\"At step \" + str(i) + \" \" + str(self.loss()))\n",
    "\n",
    "        print(\"W :\" + str(self.W))\n",
    "        print(\"b :\" + str(self.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "x6EZY02HqgMW"
   },
   "outputs": [],
   "source": [
    "def genData_model_1():\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    W = [2]\n",
    "    b = 10\n",
    "    m = 1000\n",
    "    for i in range(m):\n",
    "        x = []\n",
    "        y = 0\n",
    "\n",
    "        for j in range(len(W)):\n",
    "            xj = random.randint(0, 1)\n",
    "            y += xj * W[j]\n",
    "            x.append(xj)\n",
    "\n",
    "        y += b\n",
    "        x_train.append(x)\n",
    "        y_train.append(y)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 399,
     "output_extras": [
      {
       "item_id": 21
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17642,
     "status": "ok",
     "timestamp": 1519895034314,
     "user": {
      "displayName": "Anh T",
      "photoUrl": "//lh5.googleusercontent.com/-JhB2CiVLpeg/AAAAAAAAAAI/AAAAAAAAAQw/WH4vHOpc7Qo/s50-c-k-no/photo.jpg",
      "userId": "102252323304157157430"
     },
     "user_tz": -420
    },
    "id": "1VMMVX7OqjCq",
    "outputId": "57a50b64-8095-4a78-a81d-de90e24a6da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 0 26.3501181875\n",
      "At step 500 1.06269451524\n",
      "At step 1000 0.323924639618\n",
      "At step 1500 0.176715019809\n",
      "At step 2000 0.0992681280525\n",
      "At step 2500 0.0558217156453\n",
      "At step 3000 0.0313915460759\n",
      "At step 3500 0.0176531740818\n",
      "At step 4000 0.0099273405948\n",
      "At step 4500 0.00558268394065\n",
      "At step 5000 0.00313944703372\n",
      "At step 5500 0.00176548194064\n",
      "At step 6000 0.000992826586739\n",
      "At step 6500 0.000558320427213\n",
      "At step 7000 0.000313973964443\n",
      "At step 7500 0.000176564649157\n",
      "At step 8000 9.92919122683e-05\n",
      "At step 8500 5.58372465211e-05\n",
      "At step 9000 3.14003228242e-05\n",
      "At step 9500 1.76581105784e-05\n",
      "W :[2.008682060064042]\n",
      "b :9.99468235417\n"
     ]
    }
   ],
   "source": [
    "X_1,Y_1 = genData_model_1()\n",
    "model = model_1(X_train = X_1, Y_train = Y_1, num_step = 10000, lr = 0.003)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rUhs3uvcqoE_"
   },
   "source": [
    "**Implement with vectorize**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9K7RhJKhqtlg"
   },
   "source": [
    "**Input:** \n",
    "\n",
    "Training set contain m data point which is represented by a matrix **X** with m column and each column is one data point with n features.\n",
    "\n",
    "$$ \n",
    "X = \\begin{bmatrix}\n",
    "x^{(1)}_1 \\space \\space \\space x^{(2)}_1 \\space \\space \\space x^{(3)}_1 \\space \\space \\space ... \\space \\space \\space x^{(m)}_1 \\\\\n",
    "x^{(1)}_2 \\space \\space \\space x^{(2)}_2 \\space \\space \\space x^{(3)}_2 \\space \\space \\space ... \\space \\space \\space x^{(m)}_2 \\\\\n",
    "\\vdots \\\\\n",
    "x^{(1)}_n \\space \\space \\space x^{(2)}_n \\space \\space \\space x^{(3)}_n \\space \\space \\space ... \\space \\space \\space x^{(m)}_n \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Model: **\n",
    "$$ \\hat{Y} = WX + b$$\n",
    "\n",
    "** With: **\n",
    "\n",
    "$$ \n",
    "Y = \\begin{bmatrix}\n",
    "y^{(1)} \\space \\space \\space x^{(2)} \\space \\space \\space x^{(3)} \\space \\space \\space ... \\space \\space \\space y^{(m)}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "W = \\begin{bmatrix}\n",
    "w_{1} \\space \\space w_{2} \\space \\space w_{3} \\space \\space ... \\space \\space w_{n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "**Loss function: **\n",
    "$$ \\mathcal{L} (a) = \\frac{1}{2m} \\sum ^{m} _{i=1} (\\hat{Y} - Y)^{2} $$\n",
    "\n",
    "**Loss function derivative (gradient, slope): **\n",
    "$$ \\mathcal{L}' (W) = \\frac{\\partial \\mathcal{L}}{\\partial W} = \\frac{1}{m} (\\hat{Y} - Y) X^T $$ \n",
    "$$ \\mathcal{L}' (b) = \\frac{\\partial \\mathcal{L}}{\\partial b} = \\frac{1}{m} \\sum ^{m} _{i=1} (\\hat{Y} - Y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "PDS_rVxVqoz7"
   },
   "outputs": [],
   "source": [
    "class model_2():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 X_train,\n",
    "                 Y_train,\n",
    "                 num_step = 10000,\n",
    "                 lr = 0.1):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.num_step = num_step\n",
    "        self.lr = lr\n",
    "        \n",
    "    def initialize(self):\n",
    "        self.W = np.random.rand(1, self.X_train.shape[0])\n",
    "        self.b = 0\n",
    "        \n",
    "    # Prediction of datas point\n",
    "    # X : matrix (n x m)\n",
    "    # W : vector n dimension\n",
    "    # b : scalar\n",
    "    def predict(self,X):\n",
    "        Y_hat = np.dot(self.W, X) + self.b\n",
    "        return Y_hat\n",
    "\n",
    "    # Gradient on data set\n",
    "    # X : matrix (m x n)\n",
    "    # Y : matrix (m x 1)\n",
    "    # W : Vector n dimension\n",
    "    # b : scalar\n",
    "    def grad(self):\n",
    "        m = self.Y_train.shape[0] * 1.0\n",
    "        Y_hat = self.predict(self.X_train)\n",
    "        dW = 1/m * np.dot((Y_hat - self.Y_train), np.transpose(self.X_train))\n",
    "        db = 1/m * np.sum(Y_hat - self.Y_train)    \n",
    "        return {\"dW\":dW, \"db\" : db}\n",
    "\n",
    "    def loss(self):\n",
    "        m = self.Y_train.shape[0]\n",
    "        Y_hat = self.predict(self.X_train) \n",
    "        return 1/(2.0*m) * np.sum(np.square(Y_hat - self.Y_train))\n",
    "\n",
    "    def train(self):\n",
    "        self.initialize()\n",
    "        self.losses = []\n",
    "        for i in range(self.num_step):\n",
    "            gradient = self.grad()\n",
    "            self.W = self.W - self.lr * gradient[\"dW\"]\n",
    "            self.b = self.b - self.lr * gradient[\"db\"]\n",
    "            self.losses.append(self.loss())\n",
    "\n",
    "            if i%500==0:\n",
    "                print(\"At step \" + str(i) + \" \" + str(self.losses[-1]))\n",
    "\n",
    "        print(\"W :\" + str(self.W))\n",
    "        print(\"b :\" + str(self.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "QQO773Ryq5u2"
   },
   "outputs": [],
   "source": [
    "def genData_model_2():\n",
    "    W = np.array([[2]])\n",
    "    b = 10\n",
    "    m = 1000\n",
    "    X_train = np.random.rand(W.shape[1], m)\n",
    "    Y_train = np.dot(W, X_train) + b\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2116,
     "status": "error",
     "timestamp": 1520154004924,
     "user": {
      "displayName": "dat nguyen",
      "photoUrl": "//lh4.googleusercontent.com/-7jXM7iRnjH4/AAAAAAAAAAI/AAAAAAAAAHM/NE-2jGew0JU/s50-c-k-no/photo.jpg",
      "userId": "115618425639390237204"
     },
     "user_tz": -420
    },
    "id": "QbTekanIq8Ia",
    "outputId": "b0f0479b-6418-4fc2-fc91-b520fd76be17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 0 59866.0854928\n",
      "At step 500 1556.72320744\n",
      "At step 1000 246.848946682\n",
      "At step 1500 178.598983618\n",
      "At step 2000 144.673151469\n",
      "At step 2500 117.567047792\n",
      "At step 3000 95.5477123786\n",
      "At step 3500 77.6525923813\n",
      "At step 4000 63.1090511447\n",
      "At step 4500 51.2893674331\n",
      "At step 5000 41.6833903233\n",
      "At step 5500 33.8765150713\n",
      "At step 6000 27.531788189\n",
      "At step 6500 22.3753641508\n",
      "At step 7000 18.1846859145\n",
      "At step 7500 14.7788791092\n",
      "At step 8000 12.010945295\n",
      "At step 8500 9.76141734513\n",
      "At step 9000 7.93320311148\n",
      "At step 9500 6.44739481807\n",
      "W :[[ 2.34210199]]\n",
      "b :9.8138653596\n"
     ]
    }
   ],
   "source": [
    "X_2,Y_2 = genData_model_2()\n",
    "model = model_2(X_train = X_2, Y_train = Y_2, num_step = 10000, lr = 0.000003)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9s-YbwmUrZvH"
   },
   "source": [
    "## **Plot data to graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 347,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1519910210168,
     "user": {
      "displayName": "Viet Bui",
      "photoUrl": "//lh3.googleusercontent.com/-YK1pt62aAys/AAAAAAAAAAI/AAAAAAAABDA/FmtS-B8ZKsM/s50-c-k-no/photo.jpg",
      "userId": "116089248152786544113"
     },
     "user_tz": -420
    },
    "id": "IwjGUrthraZh",
    "outputId": "93621266-ad12-464e-e672-2a8aeb1825b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSYCBIElqGAiSJAD+P/40lnnl+fcpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118259b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot first 20 data point\n",
    "plt.plot(X_2[:,:20],Y_2[:,:20], \"bo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSZEzB8Bru_l"
   },
   "source": [
    "## **Plot loss to graph - Learning Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 347,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1519910214774,
     "user": {
      "displayName": "Viet Bui",
      "photoUrl": "//lh3.googleusercontent.com/-YK1pt62aAys/AAAAAAAAAAI/AAAAAAAABDA/FmtS-B8ZKsM/s50-c-k-no/photo.jpg",
      "userId": "116089248152786544113"
     },
     "user_tz": -420
    },
    "id": "Zt9ZprKvrcxf",
    "outputId": "8f025223-2911-44d2-ebf1-ec4008332b58"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWRWHg5mZVfn/urWMBJ6wWEQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119453d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "YopaKqunrw7n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Yiil2NA0M52F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Linear Regression.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
